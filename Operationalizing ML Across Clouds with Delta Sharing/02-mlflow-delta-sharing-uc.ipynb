{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "494c14c5-327a-4189-b452-9d70a5a49844",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🚀 Delta Sharing and Real-Time Inference with Unity Catalog Models\n",
    "\n",
    "This notebook demonstrates the full flow of consuming a shared model via Delta Sharing and deploying it for real-time inference.\n",
    "\n",
    "Steps covered:\n",
    "\n",
    "1. **Accept the shared Delta Share**  \n",
    "   - Programmatically create a catalog from the shared model using Delta Sharing APIs.\n",
    "\n",
    "2. **Ad-hoc Inference from Model Registry**  \n",
    "   - Load the shared model directly from the Unity Catalog Model Registry.\n",
    "   - Perform batch inference using the model within the cluster, assuming cluster environment compatibility.\n",
    "\n",
    "3. **Deploy a Real-Time Model Serving Endpoint**  \n",
    "   - Programmatically create a model serving endpoint using Databricks REST APIs.\n",
    "   - Host the shared model as a RESTful API for scalable, production-grade inference.\n",
    "\n",
    "4. **Perform Inference via REST API**  \n",
    "   - Send data to the deployed endpoint.\n",
    "   - Receive predictions programmatically using authentication tokens.\n",
    "\n",
    "This end-to-end workflow highlights how Delta Sharing and Unity Catalog enable cross-workspace model consumption, deployment, and real-time inferencing — all without relying on manual UI actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d972920f-1a7c-4768-aac3-6a13bde8a76e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Step 0: Accept Delta Share (Run once using SQL)\n",
    "CREATE CATALOG IF NOT EXISTS abooth_delta_share\n",
    "USING SHARE `databricks-field-eng`.`abooth_bike_sharing_model_share`\n",
    "COMMENT \"Catalog for accessing shared bike sharing model.\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eb35102-edb8-4d22-b6dd-cc1adee762bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 📦 Load and Use the Shared Model (Ad-hoc Inference)\n",
    "\n",
    "Now that the Delta Share has been accepted and the shared catalog is available, we can load the registered model directly from Unity Catalog.\n",
    "\n",
    "In this section:\n",
    "- Configure MLflow to use Unity Catalog as the model registry.\n",
    "- Load the shared model using the model URI and alias (`@staging`).\n",
    "- Prepare a small sample of new data that matches the training schema.\n",
    "- Perform ad-hoc predictions directly on the cluster without deploying a separate endpoint.\n",
    "\n",
    "This demonstrates how quickly models shared via Delta Sharing can be used for immediate inference inside a recipient workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b428195f-aa1f-4703-a362-da6da18af084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce86c7608ab443da9038b90fec8e81a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=353.1987939539919, reg_lambda=0.0 will be ignored. Current value: lambda_l2=353.1987939539919\n[LightGBM] [Warning] lambda_l1 is set=5.441545096322337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.441545096322337\nPredicted bike rentals: 48.69329265699597\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Model from Unity Catalog (Recipient Workspace)\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Configure MLflow to use Databricks Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Load the model using the shared catalog\n",
    "model_uri = \"models:/abooth_delta_share.default.bike_sharing_uc_model@staging\"\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Step 2: Prepare New Data\n",
    "new_data = pd.DataFrame({\n",
    "    'season': [1],\n",
    "    'yr': [0],\n",
    "    'mnth': [1],\n",
    "    'hr': [10],\n",
    "    'holiday': [0],\n",
    "    'weekday': [3],\n",
    "    'workingday': [1],\n",
    "    'weathersit': [1],\n",
    "    'temp': [0.3],\n",
    "    'atemp': [0.31],\n",
    "    'hum': [0.5],\n",
    "    'windspeed': [0.1]\n",
    "})\n",
    "\n",
    "# Step 3: Make Predictions\n",
    "prediction = loaded_model.predict(new_data)\n",
    "print(f\"Predicted bike rentals: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb9c849a-f11b-47f1-9245-7c14c031a224",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 🚀 Deploy the Shared Model to Real-Time Serving\n",
    "\n",
    "In this section, we deploy the shared and registered model as a real-time serving endpoint using Databricks Model Serving.\n",
    "\n",
    "Steps:\n",
    "- Programmatically create a new serving endpoint via the Databricks REST API.\n",
    "- Configure the endpoint to serve the shared model version from Unity Catalog.\n",
    "- Enable auto-scaling options like `scale_to_zero` for cost efficiency.\n",
    "\n",
    "Once the endpoint is active, we will send inference requests over HTTP by authenticating with a Databricks personal access token (PAT).  \n",
    "This enables scalable, production-grade, low-latency predictions from the shared model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0654f2-bd1d-4bab-b154-dcfa55efbe51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created serving endpoint: abooth_bike_serving_endpoint\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Step 1: Define variables\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "WORKSPACE_URL = \"https://xxxxxxxx.azuredatabricks.net\"  # your workspace\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# Step 2: Define your serving endpoint config\n",
    "endpoint_name = \"abooth_bike_serving_endpoint\"\n",
    "\n",
    "create_payload = {\n",
    "    \"name\": endpoint_name,\n",
    "    \"config\": {\n",
    "        \"served_models\": [\n",
    "            {\n",
    "                \"model_name\": \"abooth_delta_share.default.bike_sharing_uc_model\",\n",
    "                \"model_version\": \"1\",  # Use version number\n",
    "                \"workload_type\": \"CPU\",  # or \"GPU\"\n",
    "                \"workload_size\": \"Small\",  # Small / Medium / Large\n",
    "                \"scale_to_zero_enabled\": True,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 3: Make the request to create endpoint\n",
    "create_url = f\"{WORKSPACE_URL}/api/2.0/serving-endpoints\"\n",
    "response = requests.post(create_url, headers=headers, data=json.dumps(create_payload))\n",
    "\n",
    "# Step 4: Check result\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully created serving endpoint: {endpoint_name}\")\n",
    "else:\n",
    "    print(f\"Failed to create serving endpoint: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c362e519-8b17-4a5d-ac5b-55d6aa396b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'error_code': 'RESOURCE_DOES_NOT_EXIST',\n",
       " 'message': 'The given endpoint does not exist.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Step 1: Authenticate to Databricks by retrieving the notebook's API token\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "# Step 2: Define the workspace URL and model serving endpoint URL\n",
    "WORKSPACE_URL = \"https://xxxxxxxx.azuredatabricks.net\"  # your workspace\n",
    "ENDPOINT = f\"{WORKSPACE_URL}/serving-endpoints/abooth_bike_serving_endpoint/invocations\"\n",
    "\n",
    "# Step 3: Set the HTTP headers, including the authorization token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# Step 4: Build the request payload by converting the input DataFrame to the required format\n",
    "payload = {\"dataframe_split\": new_data.to_dict(orient=\"split\")}\n",
    "\n",
    "# Step 5: Send the POST request to the serving endpoint for inference\n",
    "response = requests.post(ENDPOINT, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "# Step 6: Parse and display the prediction results\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99bd0114-2f7e-428a-b1a0-9a0f77631ea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🏁 Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we demonstrated how to:\n",
    "\n",
    "- Accept a Delta Share containing a Unity Catalog-registered model.\n",
    "- Load and perform ad-hoc inference on the shared model.\n",
    "- Deploy the shared model to a real-time serving endpoint.\n",
    "- Perform predictions using a REST API with secure authentication.\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Next Steps: A/B Testing with Shared Models\n",
    "\n",
    "If multiple models are available — for example, if a previously shared **production model** exists alongside a newly shared **candidate model** — we can extend this workflow to enable **A/B testing**.\n",
    "\n",
    "Potential next steps include:\n",
    "\n",
    "- **Create multiple serving endpoints** for the \"Prod\" model and the \"Staging\" model.\n",
    "- **Route traffic** dynamically between models based on a defined split (e.g., 50/50, 80/20).\n",
    "- **Log model predictions and outcomes** into a centralized Delta table for comparison.\n",
    "- **Analyze A/B test results** to determine which model performs better on real-world data.\n",
    "- **Promote the winning model** by updating aliases (e.g., setting the `@prod` alias) and refreshing the serving endpoint.\n",
    "\n",
    "By using Delta Sharing and Unity Catalog together, model consumers can easily experiment with multiple models across workspaces without needing to duplicate or manually manage artifacts.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3106337408899177,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02-mlflow-delta-sharing-uc",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}